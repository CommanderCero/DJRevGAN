<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Project Page: Reversible GANs for Memory-efficient Image-to-Image Translation</title>
<link media="all" href="style.css" type="text/css" rel="StyleSheet">
  
</head>

<body>
<div id="main">
  <center>
    <h1>Reversible GANs for Memory-efficient Image-to-Image Translation</h1>
  </center>
  <center>
    <h2>
      <a href="https://tychovdo.github.io/">Tycho F.A. van der Ouderaa</a>&nbsp;&nbsp;&nbsp;
      <a href="https://deworrall92.github.io/">Daniel E. Worrall</a>
    </h2>
  </center>
  <center>
    <h2>
      University of Amsterdam
    </h2>
  </center>
  <center>
    <h2>
      In CVPR 2019
    </h2>
  </center>
  <center>
    <h2>
      <strong>
        <a href="https://arxiv.org/abs/1902.02729">Paper</a> |
        <a href="https://github.com/tychovdo/RevGAN">Code</a>
      </strong>
    </h2>
  </center>
  <center>
    <img src="revgan_im1.png" width=50%></img>
  </center>
  <h2>Abstract</h2>
  <p>
The Pix2pix and CycleGAN losses have vastly
improved the qualitative and quantitative visual quality of
results in image-to-image translation tasks. We extend this
framework by exploring approximately invertible architectures in 2D and 3D 
which are well suited to these losses. These architectures
are approximately invertible by design and thus partially
satisfy cycle-consistency before training even begins.
Furthermore, since invertible architectures have constant
memory complexity in depth, these models can be built arbitrarily
deep. We are able to demonstrate superior quantitative
output on the Cityscapes and Maps datasets at near
constant memory budget.
  </p>
  <h2>Acknowledgements</h2>
  <p>
We grateful to the Diagnostic Image Analysis Group (DIAG) of the Radboud University Medical Center, and in particular Prof. Dr. Bram van Ginneken for his collaboration on this project.
We also thank the Netherlands Organisation for Scientific Research (NWO) for supporting this research and providing computational resources.
  </p>
</div>
</body>
</html>
